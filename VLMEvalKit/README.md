<div align="center">

<b>A Toolkit for Evaluating Large Vision-Language Models. </b>

English | [ç®€ä½“ä¸­æ–‡](./docs/zh-CN/README_zh-CN.md)

<a href="https://rank.opencompass.org.cn/leaderboard-multimodal">ğŸ† OC Learderboard </a> â€¢
<a href="#%EF%B8%8F-quickstart">ğŸ—ï¸Quickstart </a> â€¢
<a href="#-datasets-models-and-evaluation-results">ğŸ“ŠDatasets & Models </a> â€¢
<a href="#%EF%B8%8F-development-guide">ğŸ› ï¸Development </a>

<a href="https://huggingface.co/spaces/opencompass/open_vlm_leaderboard">ğŸ¤— HF Leaderboard</a> â€¢
<a href="https://huggingface.co/datasets/VLMEval/OpenVLMRecords">ğŸ¤— Evaluation Records</a> â€¢
<a href="https://huggingface.co/spaces/opencompass/openvlm_video_leaderboard">ğŸ¤— HF Video Leaderboard</a> â€¢

<a href="https://discord.gg/evDT4GZmxN">ğŸ”Š Discord</a> â€¢
<a href="https://www.arxiv.org/abs/2407.11691">ğŸ“ Report</a> â€¢
<a href="#-the-goal-of-vlmevalkit">ğŸ¯Goal </a> â€¢
<a href="#%EF%B8%8F-citation">ğŸ–Šï¸Citation </a>
</div>

**VLMEvalKit** (the python package name is **vlmeval**) is an **open-source evaluation toolkit** of **large vision-language models (LVLMs)**. It enables **one-command evaluation** of LVLMs on various benchmarks, without the heavy workload of data preparation under multiple repositories. In VLMEvalKit, we adopt **generation-based evaluation** for all LVLMs, and provide the evaluation results obtained with both **exact matching** and **LLM-based answer extraction**.

## ğŸ—ï¸ QuickStart

See [[QuickStart](./docs/en/Quickstart.md) | [å¿«é€Ÿå¼€å§‹](./docs/zh-CN/Quickstart.md)] for a quick start guide.

## ğŸ“Š Demonstration

```python
# Demo
from vlmeval.config import supported_VLM
model = supported_VLM['NEO1_0-2B-SFT']()
# Forward Single Image
ret = model.generate(['assets/apple.jpg', 'What is in this image?'])
print(ret)  # The image features a red apple with a leaf on it.
# Forward Multiple Images
ret = model.generate(['assets/apple.jpg', 'assets/apple.jpg', 'How many apples are there in the provided images? '])
print(ret)  # There are two apples in the provided images.
```